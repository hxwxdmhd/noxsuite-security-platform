{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NoxSuite Security Platform - AI/ML Demo\n",
    "\n",
    "This notebook demonstrates the AI/ML capabilities integrated into the NoxSuite Security Platform.\n",
    "\n",
    "## Features Demonstrated:\n",
    "- Security model training on log data\n",
    "- Anomaly detection for login patterns\n",
    "- Risk scoring for users and sessions\n",
    "- Real-time threat assessment\n",
    "\n",
    "## Requirements:\n",
    "- Python 3.12+\n",
    "- All ML dependencies from requirements.txt\n",
    "- Sample security log data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Add the project root to Python path\n",
    "sys.path.append('..')\n",
    "\n",
    "# Import NoxSuite ML modules\n",
    "try:\n",
    "    from ml.model_training import SecurityModelTrainer, create_sample_security_data\n",
    "    from ml.anomaly_detection import AnomalyDetector, create_sample_system_metrics\n",
    "    from ml.predictive_engine import RiskScoreEngine, create_sample_training_data\n",
    "    print(\"✅ NoxSuite ML modules imported successfully\")\n",
    "except ImportError as e:\n",
    "    print(f\"❌ Error importing ML modules: {e}\")\n",
    "    print(\"Please ensure all dependencies are installed: pip install -r requirements.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Security Model Training Demo\n",
    "\n",
    "Demonstrate training ML models on security log data for threat detection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the Security Model Trainer\n",
    "trainer = SecurityModelTrainer(model_dir=\"../models\")\n",
    "\n",
    "# Create sample security log data\n",
    "print(\"Creating sample security log data...\")\n",
    "security_logs = create_sample_security_data(1000)\n",
    "\n",
    "print(f\"Generated {len(security_logs)} security log entries\")\n",
    "print(\"\\nSample data:\")\n",
    "security_logs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the security log data\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "# Login status distribution\n",
    "security_logs['status'].value_counts().plot(kind='bar', ax=axes[0,0], title='Login Status Distribution')\n",
    "\n",
    "# Failed login patterns by hour\n",
    "security_logs['hour'] = pd.to_datetime(security_logs['timestamp']).dt.hour\n",
    "failed_by_hour = security_logs[security_logs['status'] == 'failed'].groupby('hour').size()\n",
    "failed_by_hour.plot(kind='line', ax=axes[0,1], title='Failed Logins by Hour')\n",
    "\n",
    "# User activity distribution\n",
    "security_logs['user_id'].value_counts().plot(kind='bar', ax=axes[1,0], title='User Activity Distribution')\n",
    "\n",
    "# IP address distribution\n",
    "security_logs['ip_address'].value_counts().plot(kind='bar', ax=axes[1,1], title='IP Address Distribution')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train anomaly detection model\n",
    "print(\"Training anomaly detection model...\")\n",
    "anomaly_results = trainer.train_anomaly_detector(security_logs, \"demo_anomaly_model\")\n",
    "\n",
    "print(\"\\nAnomaly Detection Results:\")\n",
    "for key, value in anomaly_results.items():\n",
    "    print(f\"{key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train classification model for threat detection\n",
    "print(\"Training threat classification model...\")\n",
    "classification_results = trainer.train_classification_model(security_logs, \"demo_threat_classifier\")\n",
    "\n",
    "print(\"\\nThreat Classification Results:\")\n",
    "for key, value in classification_results.items():\n",
    "    print(f\"{key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Real-time Anomaly Detection Demo\n",
    "\n",
    "Demonstrate real-time anomaly detection on system metrics and user behavior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize anomaly detector\n",
    "detector = AnomalyDetector()\n",
    "\n",
    "# Simulate real-time system monitoring\n",
    "print(\"Simulating real-time system monitoring...\")\n",
    "all_alerts = []\n",
    "system_metrics_history = []\n",
    "\n",
    "for i in range(20):\n",
    "    # Generate system metrics\n",
    "    metrics = create_sample_system_metrics()\n",
    "    system_metrics_history.append(metrics)\n",
    "    \n",
    "    # Detect anomalies\n",
    "    alerts = detector.detect_system_metric_anomalies(metrics)\n",
    "    all_alerts.extend(alerts)\n",
    "    \n",
    "    if alerts:\n",
    "        print(f\"Iteration {i+1}: {len(alerts)} alerts detected\")\n",
    "        for alert in alerts:\n",
    "            print(f\"  - {alert.severity.upper()}: {alert.description}\")\n",
    "\n",
    "print(f\"\\nTotal alerts generated: {len(all_alerts)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize system metrics and anomalies\n",
    "metrics_df = pd.DataFrame(system_metrics_history)\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "# Plot each metric\n",
    "metrics_df['cpu_usage'].plot(ax=axes[0,0], title='CPU Usage Over Time')\n",
    "axes[0,0].set_ylabel('CPU %')\n",
    "\n",
    "metrics_df['memory_usage'].plot(ax=axes[0,1], title='Memory Usage Over Time')\n",
    "axes[0,1].set_ylabel('Memory %')\n",
    "\n",
    "metrics_df['network_throughput'].plot(ax=axes[1,0], title='Network Throughput Over Time')\n",
    "axes[1,0].set_ylabel('Throughput')\n",
    "\n",
    "metrics_df['active_connections'].plot(ax=axes[1,1], title='Active Connections Over Time')\n",
    "axes[1,1].set_ylabel('Connections')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get alert summary\n",
    "alert_summary = detector.get_alert_summary(hours=24)\n",
    "\n",
    "print(\"Alert Summary (Last 24 hours):\")\n",
    "print(f\"Total alerts: {alert_summary['total_alerts']}\")\n",
    "print(f\"By severity: {alert_summary['by_severity']}\")\n",
    "print(f\"By type: {alert_summary['by_type']}\")\n",
    "\n",
    "if alert_summary['latest_alert']:\n",
    "    print(f\"Latest alert: {alert_summary['latest_alert']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Risk Scoring Engine Demo\n",
    "\n",
    "Demonstrate predictive risk scoring for users, sessions, and IP addresses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize risk scoring engine\n",
    "risk_engine = RiskScoreEngine(model_dir=\"../models\")\n",
    "\n",
    "# Create sample training data for risk models\n",
    "print(\"Creating sample training data for risk models...\")\n",
    "training_data = create_sample_training_data(500)\n",
    "\n",
    "print(f\"Generated {len(training_data)} training samples\")\n",
    "print(\"\\nSample training data:\")\n",
    "training_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize risk score distribution\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "# Risk score distribution\n",
    "training_data['risk_score'].hist(bins=30, ax=axes[0,0], title='Risk Score Distribution')\n",
    "axes[0,0].set_xlabel('Risk Score')\n",
    "axes[0,0].set_ylabel('Frequency')\n",
    "\n",
    "# Risk vs Failed Login Ratio\n",
    "axes[0,1].scatter(training_data['failed_login_ratio'], training_data['risk_score'], alpha=0.6)\n",
    "axes[0,1].set_xlabel('Failed Login Ratio')\n",
    "axes[0,1].set_ylabel('Risk Score')\n",
    "axes[0,1].set_title('Risk Score vs Failed Login Ratio')\n",
    "\n",
    "# Risk vs Privilege Escalation\n",
    "axes[1,0].scatter(training_data['privilege_escalation_attempts'], training_data['risk_score'], alpha=0.6)\n",
    "axes[1,0].set_xlabel('Privilege Escalation Attempts')\n",
    "axes[1,0].set_ylabel('Risk Score')\n",
    "axes[1,0].set_title('Risk Score vs Privilege Escalation')\n",
    "\n",
    "# Risk vs External IP Usage\n",
    "axes[1,1].scatter(training_data['external_ip_usage'], training_data['risk_score'], alpha=0.6)\n",
    "axes[1,1].set_xlabel('External IP Usage')\n",
    "axes[1,1].set_ylabel('Risk Score')\n",
    "axes[1,1].set_title('Risk Score vs External IP Usage')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train risk scoring models\n",
    "print(\"Training risk scoring models...\")\n",
    "training_results = risk_engine.train_risk_models(training_data)\n",
    "\n",
    "print(\"\\nTraining Results:\")\n",
    "print(f\"Best model: {training_results['best_model']}\")\n",
    "print(f\"Total samples: {training_results['total_samples']}\")\n",
    "print(f\"Feature count: {training_results['feature_count']}\")\n",
    "\n",
    "print(\"\\nModel Performance:\")\n",
    "for model_name, metrics in training_results['model_results'].items():\n",
    "    print(f\"{model_name}:\")\n",
    "    print(f\"  - MAE: {metrics['mae']:.4f}\")\n",
    "    print(f\"  - MSE: {metrics['mse']:.4f}\")\n",
    "    print(f\"  - R²: {metrics['r2']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test user risk scoring\n",
    "print(\"Testing user risk scoring...\")\n",
    "\n",
    "# Get sample user data\n",
    "sample_user_data = training_data[training_data['entity_id'] == 'user_5'].copy()\n",
    "sample_user_data['timestamp'] = pd.date_range('2024-01-01', periods=len(sample_user_data), freq='H')\n",
    "sample_user_data['ip_address'] = ['192.168.1.10'] * len(sample_user_data)\n",
    "sample_user_data['status'] = ['success'] * len(sample_user_data)\n",
    "\n",
    "# Calculate risk score\n",
    "user_risk = risk_engine.calculate_user_risk_score('user_5', sample_user_data)\n",
    "\n",
    "print(f\"\\nUser Risk Assessment for {user_risk.entity_id}:\")\n",
    "print(f\"Risk Score: {user_risk.risk_score:.3f}\")\n",
    "print(f\"Risk Level: {user_risk.risk_level.value.upper()}\")\n",
    "print(f\"Confidence: {user_risk.confidence:.3f}\")\n",
    "print(f\"Prediction Horizon: {user_risk.prediction_horizon}\")\n",
    "\n",
    "print(f\"\\nRisk Factors:\")\n",
    "for factor, value in user_risk.factors.items():\n",
    "    print(f\"  - {factor}: {value:.3f}\")\n",
    "\n",
    "print(f\"\\nRecommendations:\")\n",
    "for rec in user_risk.recommendations:\n",
    "    print(f\"  - {rec}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test session risk scoring\n",
    "print(\"Testing session risk scoring...\")\n",
    "\n",
    "# Create sample session data\n",
    "sample_sessions = [\n",
    "    {\n",
    "        'session_id': 'session_normal',\n",
    "        'duration_minutes': 30,\n",
    "        'pages_accessed': 5,\n",
    "        'failed_attempts': 0,\n",
    "        'ip_address': '192.168.1.100',\n",
    "        'new_device': False,\n",
    "        'user_agent': 'Mozilla/5.0...'\n",
    "    },\n",
    "    {\n",
    "        'session_id': 'session_suspicious',\n",
    "        'duration_minutes': 120,\n",
    "        'pages_accessed': 50,\n",
    "        'failed_attempts': 5,\n",
    "        'ip_address': '203.0.113.1',\n",
    "        'new_device': True,\n",
    "        'user_agent': 'bot/1.0'\n",
    "    }\n",
    "]\n",
    "\n",
    "for session_data in sample_sessions:\n",
    "    session_id = session_data.pop('session_id')\n",
    "    session_risk = risk_engine.calculate_session_risk_score(session_id, session_data)\n",
    "    \n",
    "    print(f\"\\nSession Risk Assessment for {session_risk.entity_id}:\")\n",
    "    print(f\"Risk Score: {session_risk.risk_score:.3f}\")\n",
    "    print(f\"Risk Level: {session_risk.risk_level.value.upper()}\")\n",
    "    print(f\"Recommendations: {', '.join(session_risk.recommendations)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Integration Demo\n",
    "\n",
    "Demonstrate how all ML components work together for comprehensive security monitoring."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comprehensive security monitoring simulation\n",
    "print(\"Running comprehensive security monitoring simulation...\")\n",
    "\n",
    "# Simulate 24 hours of monitoring\n",
    "monitoring_results = {\n",
    "    'anomaly_alerts': [],\n",
    "    'risk_assessments': [],\n",
    "    'model_predictions': []\n",
    "}\n",
    "\n",
    "for hour in range(24):\n",
    "    print(f\"\\nHour {hour:02d}:00 - Security Monitoring\")\n",
    "    \n",
    "    # 1. System metrics monitoring\n",
    "    metrics = create_sample_system_metrics()\n",
    "    anomaly_alerts = detector.detect_system_metric_anomalies(metrics)\n",
    "    \n",
    "    if anomaly_alerts:\n",
    "        monitoring_results['anomaly_alerts'].extend(anomaly_alerts)\n",
    "        print(f\"  🚨 {len(anomaly_alerts)} anomalies detected\")\n",
    "    \n",
    "    # 2. User risk assessment (simulate random user)\n",
    "    if hour % 4 == 0:  # Assess users every 4 hours\n",
    "        user_id = f\"user_{hour // 4}\"\n",
    "        user_data = training_data[training_data['entity_id'] == 'user_1'].head(10).copy()\n",
    "        user_data['timestamp'] = pd.date_range('2024-01-01', periods=len(user_data), freq='H')\n",
    "        \n",
    "        user_risk = risk_engine.calculate_user_risk_score(user_id, user_data)\n",
    "        monitoring_results['risk_assessments'].append(user_risk)\n",
    "        \n",
    "        if user_risk.risk_level.value in ['high', 'critical']:\n",
    "            print(f\"  ⚠️  High risk user detected: {user_id} (Risk: {user_risk.risk_score:.3f})\")\n",
    "\n",
    "print(f\"\\n📊 Monitoring Summary:\")\n",
    "print(f\"Total anomaly alerts: {len(monitoring_results['anomaly_alerts'])}\")\n",
    "print(f\"Total risk assessments: {len(monitoring_results['risk_assessments'])}\")\n",
    "\n",
    "# Alert severity breakdown\n",
    "severity_counts = {}\n",
    "for alert in monitoring_results['anomaly_alerts']:\n",
    "    severity_counts[alert.severity] = severity_counts.get(alert.severity, 0) + 1\n",
    "\n",
    "print(f\"Alert severity breakdown: {severity_counts}\")\n",
    "\n",
    "# Risk level breakdown\n",
    "risk_counts = {}\n",
    "for assessment in monitoring_results['risk_assessments']:\n",
    "    level = assessment.risk_level.value\n",
    "    risk_counts[level] = risk_counts.get(level, 0) + 1\n",
    "\n",
    "print(f\"Risk level breakdown: {risk_counts}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create final summary visualization\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "# Alert severity distribution\n",
    "if severity_counts:\n",
    "    pd.Series(severity_counts).plot(kind='bar', ax=axes[0,0], title='Anomaly Alerts by Severity')\n",
    "    axes[0,0].set_ylabel('Count')\n",
    "    axes[0,0].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Risk level distribution\n",
    "if risk_counts:\n",
    "    pd.Series(risk_counts).plot(kind='bar', ax=axes[0,1], title='Risk Assessments by Level')\n",
    "    axes[0,1].set_ylabel('Count')\n",
    "    axes[0,1].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Risk scores over time\n",
    "if monitoring_results['risk_assessments']:\n",
    "    risk_scores = [r.risk_score for r in monitoring_results['risk_assessments']]\n",
    "    pd.Series(risk_scores).plot(ax=axes[1,0], title='Risk Scores Over Time')\n",
    "    axes[1,0].set_ylabel('Risk Score')\n",
    "    axes[1,0].set_xlabel('Assessment #')\n",
    "\n",
    "# Alert timeline\n",
    "if monitoring_results['anomaly_alerts']:\n",
    "    alert_times = [i for i, alert in enumerate(monitoring_results['anomaly_alerts'])]\n",
    "    alert_scores = [alert.score for alert in monitoring_results['anomaly_alerts']]\n",
    "    axes[1,1].scatter(alert_times, alert_scores, alpha=0.7)\n",
    "    axes[1,1].set_title('Anomaly Alert Scores Timeline')\n",
    "    axes[1,1].set_xlabel('Alert #')\n",
    "    axes[1,1].set_ylabel('Anomaly Score')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n✅ AI/ML Integration Demo Complete!\")\n",
    "print(\"\\nThe NoxSuite Security Platform now includes:\")\n",
    "print(\"- Advanced ML-based anomaly detection\")\n",
    "print(\"- Predictive risk scoring for users and sessions\")\n",
    "print(\"- Real-time threat assessment capabilities\")\n",
    "print(\"- Comprehensive security model training\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}