{
  "ollama": {
    "name": "Ollama",
    "provider": "ollama",
    "endpoint": "http://localhost:11434",
    "port": 11434,
    "process_name": "ollama",
    "start_command": "ollama serve",
    "test_prompt": "Say hello briefly",
    "status": "⚪",
    "last_checked": null,
    "latency_ms": null,
    "error_message": null,
    "restart_attempts": 0,
    "max_restart_attempts": 3,
    "current_model": null
  },
  "lmstudio": {
    "name": "LM Studio",
    "provider": "lmstudio",
    "endpoint": "http://localhost:1234",
    "port": 1234,
    "process_name": "lmstudio",
    "start_command": "lmstudio --server",
    "test_prompt": "Hello, respond with just 'Hi'",
    "status": "⚪",
    "last_checked": null,
    "latency_ms": null,
    "error_message": null,
    "restart_attempts": 0,
    "max_restart_attempts": 3,
    "current_model": null
  },
  "localai": {
    "name": "LocalAI",
    "provider": "localai",
    "endpoint": "http://localhost:8080",
    "port": 8080,
    "process_name": "local-ai",
    "start_command": "local-ai",
    "test_prompt": "Say hello",
    "status": "⚪",
    "last_checked": null,
    "latency_ms": null,
    "error_message": null,
    "restart_attempts": 0,
    "max_restart_attempts": 3,
    "current_model": null
  },
  "gpt4all": {
    "name": "GPT4All",
    "provider": "gpt4all",
    "endpoint": "http://localhost:4891",
    "port": 4891,
    "process_name": "gpt4all",
    "start_command": "gpt4all --server",
    "test_prompt": "Hello",
    "status": "⚪",
    "last_checked": null,
    "latency_ms": null,
    "error_message": null,
    "restart_attempts": 0,
    "max_restart_attempts": 3,
    "current_model": null
  },
  "oobabooga": {
    "name": "Oobabooga Text-Gen",
    "provider": "oobabooga",
    "endpoint": "http://localhost:7860",
    "port": 7860,
    "process_name": "text-generation-webui",
    "start_command": "python server.py --listen",
    "test_prompt": "Hello, respond briefly",
    "status": "⚪",
    "last_checked": null,
    "latency_ms": null,
    "error_message": null,
    "restart_attempts": 0,
    "max_restart_attempts": 3,
    "current_model": null
  }
}
